"""
ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ìˆ˜ì§‘í•˜ëŠ” ëª¨ë“ˆ
"""
import logging
from datetime import datetime
from typing import List, Dict, Any
from app.services.collector import fetch_google_trends, fetch_reddit_subreddit
from app.services.news_collector import fetch_multiple_news_sources
from app.services.github_collector import fetch_github_trending
from app.services.youtube_collector import fetch_youtube_trending, fetch_youtube_search

logger = logging.getLogger("hourly_pulse")

async def collect_all_sources() -> Dict[str, List[Dict[str, Any]]]:
    """
    ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    Returns:
        ì†ŒìŠ¤ë³„ë¡œ ë¶„ë¥˜ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    logger.info("ğŸš€ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    
    collected_data = {
        "reddit": [],
        "reddit_subreddits": [],
        "news": [],
        "github": [],
        "youtube": []
    }
    
    # 1. Reddit Popular ìˆ˜ì§‘
    try:
        reddit_posts = await fetch_google_trends()  # ì´ì œ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        collected_data["reddit"] = reddit_posts  # ì§ì ‘ í• ë‹¹ (ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ í˜•íƒœ)
        logger.info(f"âœ… Reddit Popular: {len(collected_data['reddit'])}ê°œ ìˆ˜ì§‘")
    except Exception as e:
        logger.error(f"âŒ Reddit Popular ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
    
    # 2. Reddit íŠ¹ì • ì„œë¸Œë ˆë”§ ìˆ˜ì§‘ (4K RPM í™œìš©í•˜ì—¬ ìˆ˜ì§‘ëŸ‰ ì¦ê°€)
    try:
        subreddits = ["worldnews", "technology", "korea", "news", "programming", "science", "business", "politics", "entertainment", "gaming"]
        all_subreddit_posts = []
        for subreddit in subreddits:
            posts = await fetch_reddit_subreddit(subreddit, limit=50)  # 5 -> 50ìœ¼ë¡œ ì¦ê°€
            all_subreddit_posts.extend(posts)
        collected_data["reddit_subreddits"] = all_subreddit_posts
        logger.info(f"âœ… Reddit ì„œë¸Œë ˆë”§: {len(collected_data['reddit_subreddits'])}ê°œ ìˆ˜ì§‘")
    except Exception as e:
        logger.error(f"âŒ Reddit ì„œë¸Œë ˆë”§ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
    
    # 3. ë‰´ìŠ¤ ìˆ˜ì§‘
    try:
        news_items = await fetch_multiple_news_sources()
        collected_data["news"] = news_items
        logger.info(f"âœ… ë‰´ìŠ¤: {len(collected_data['news'])}ê°œ ìˆ˜ì§‘")
    except Exception as e:
        logger.error(f"âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
    
    # 4. GitHub Trending ìˆ˜ì§‘
    try:
        github_repos = await fetch_github_trending()
        collected_data["github"] = github_repos
        logger.info(f"âœ… GitHub: {len(collected_data['github'])}ê°œ ìˆ˜ì§‘")
    except Exception as e:
        logger.error(f"âŒ GitHub ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
    
    # 5. YouTube ìˆ˜ì§‘
    try:
        youtube_trending = await fetch_youtube_trending(region_code="KR")
        # ê²€ìƒ‰ë„ ì¶”ê°€ (ì„ íƒì )
        # youtube_search = await fetch_youtube_search(query="trending")
        collected_data["youtube"] = youtube_trending
        logger.info(f"âœ… YouTube: {len(collected_data['youtube'])}ê°œ ìˆ˜ì§‘")
    except Exception as e:
        logger.error(f"âŒ YouTube ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
    
    total_items = sum(len(items) for items in collected_data.values())
    logger.info(f"ğŸ“Š ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ! ì´ {total_items}ê°œ ì•„ì´í…œ")
    
    return collected_data

