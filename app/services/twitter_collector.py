"""
Twitter/X APIë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ë Œë”© ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ëª¨ë“ˆ
"""
import httpx
import logging
import os
from datetime import datetime
from typing import List, Dict, Any
from dotenv import load_dotenv

load_dotenv()
logger = logging.getLogger("hourly_pulse")

async def fetch_twitter_trends(bearer_token: str = None) -> List[Dict[str, Any]]:
    """
    Twitter/X APIë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ë Œë”© í† í”½ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    Args:
        bearer_token: Twitter Bearer Token (í™˜ê²½ë³€ìˆ˜ TWITTER_BEARER_TOKENì—ì„œë„ ì½ìŒ)
    
    Returns:
        íŠ¸ë Œë”© í† í”½ ë¦¬ìŠ¤íŠ¸
    """
    # Bearer Token ê°€ì ¸ì˜¤ê¸°
    token = bearer_token or os.getenv("TWITTER_BEARER_TOKEN")
    
    if not token:
        logger.warning("âš ï¸ Twitter Bearer Tokenì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ TWITTER_BEARER_TOKENì„ ì„¤ì •í•˜ì„¸ìš”.")
        return []
    
    headers = {
        "Authorization": f"Bearer {token}",
        "User-Agent": "HourlyPulse/1.0"
    }
    
    # íŠ¸ë Œë”© í† í”½ ì¡°íšŒ (WOEID: 1 = ì „ì„¸ê³„, 23424868 = í•œêµ­)
    # ì°¸ê³ : Twitter API v2ëŠ” íŠ¸ë Œë”© í† í”½ ì—”ë“œí¬ì¸íŠ¸ê°€ ì œí•œì ì…ë‹ˆë‹¤
    # ëŒ€ì•ˆ: íŠ¸ìœ— ê²€ìƒ‰ API ì‚¬ìš©
    url = "https://api.twitter.com/2/tweets/search/recent"
    
    # ìµœê·¼ ì¸ê¸° íŠ¸ìœ— ê²€ìƒ‰ (ì˜ˆ: ë†’ì€ ì¢‹ì•„ìš” ìˆ˜)
    params = {
        "query": "lang:en -is:retweet",  # ì˜ì–´, ë¦¬íŠ¸ìœ— ì œì™¸
        "max_results": 10,
        "tweet.fields": "public_metrics,created_at,text",
        "sort_order": "relevancy"
    }
    
    logger.info("ğŸ¦ Twitter/X íŠ¸ë Œë”© ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    
    async with httpx.AsyncClient(timeout=10.0, headers=headers) as client:
        try:
            response = await client.get(url, params=params)
            
            if response.status_code == 401:
                logger.error("âŒ Twitter API ì¸ì¦ ì‹¤íŒ¨. Bearer Tokenì„ í™•ì¸í•˜ì„¸ìš”.")
                return []
            elif response.status_code == 429:
                logger.warning("âš ï¸ Twitter API ìš”ì²­ í•œë„ ì´ˆê³¼. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                return []
            
            response.raise_for_status()
            data = response.json()
            
            trends = []
            if "data" in data:
                for tweet in data["data"]:
                    metrics = tweet.get("public_metrics", {})
                    trend_item = {
                        "source": "Twitter/X",
                        "title": tweet.get("text", "")[:200],  # ìµœëŒ€ 200ì
                        "url": f"https://twitter.com/i/web/status/{tweet.get('id', '')}",
                        "likes": metrics.get("like_count", 0),
                        "retweets": metrics.get("retweet_count", 0),
                        "replies": metrics.get("reply_count", 0),
                        "created_at": tweet.get("created_at", ""),
                        "collected_at": datetime.now().isoformat()
                    }
                    trends.append(trend_item)
            
            if trends:
                logger.info(f"âœ… Twitter/X ìˆ˜ì§‘ ì„±ê³µ! {len(trends)}ê°œ íŠ¸ìœ— ë°œê²¬")
            return trends
            
        except httpx.HTTPStatusError as e:
            logger.error(f"âŒ Twitter API HTTP ì˜¤ë¥˜ ({e.response.status_code}): {e}")
            if e.response.status_code == 403:
                logger.error("ğŸ’¡ Twitter API v2 Basic ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. https://developer.twitter.com/ ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
            return []
        except Exception as e:
            logger.error(f"âŒ Twitter/X ìˆ˜ì§‘ ì‹¤íŒ¨: {type(e).__name__} - {e}")
            return []


async def fetch_twitter_hashtags(bearer_token: str = None, hashtag: str = "trending") -> List[Dict[str, Any]]:
    """
    íŠ¹ì • í•´ì‹œíƒœê·¸ì˜ íŠ¸ìœ—ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    Args:
        bearer_token: Twitter Bearer Token
        hashtag: ê²€ìƒ‰í•  í•´ì‹œíƒœê·¸ (ì˜ˆ: "trending", "news", "tech")
    
    Returns:
        íŠ¸ìœ— ë¦¬ìŠ¤íŠ¸
    """
    token = bearer_token or os.getenv("TWITTER_BEARER_TOKEN")
    
    if not token:
        return []
    
    headers = {
        "Authorization": f"Bearer {token}",
        "User-Agent": "HourlyPulse/1.0"
    }
    
    url = "https://api.twitter.com/2/tweets/search/recent"
    params = {
        "query": f"#{hashtag} -is:retweet lang:en",
        "max_results": 10,
        "tweet.fields": "public_metrics,created_at,text"
    }
    
    logger.info(f"ğŸ¦ Twitter í•´ì‹œíƒœê·¸ #{hashtag} ìˆ˜ì§‘ ì‹œì‘...")
    
    async with httpx.AsyncClient(timeout=10.0, headers=headers) as client:
        try:
            response = await client.get(url, params=params)
            response.raise_for_status()
            
            data = response.json()
            tweets = []
            
            if "data" in data:
                for tweet in data["data"]:
                    metrics = tweet.get("public_metrics", {})
                    tweet_item = {
                        "source": f"Twitter #{hashtag}",
                        "title": tweet.get("text", "")[:200],
                        "url": f"https://twitter.com/i/web/status/{tweet.get('id', '')}",
                        "hashtag": hashtag,
                        "likes": metrics.get("like_count", 0),
                        "retweets": metrics.get("retweet_count", 0),
                        "collected_at": datetime.now().isoformat()
                    }
                    tweets.append(tweet_item)
            
            if tweets:
                logger.info(f"âœ… Twitter #{hashtag} ìˆ˜ì§‘ ì„±ê³µ! {len(tweets)}ê°œ íŠ¸ìœ— ë°œê²¬")
            return tweets
            
        except Exception as e:
            logger.error(f"âŒ Twitter #{hashtag} ìˆ˜ì§‘ ì‹¤íŒ¨: {type(e).__name__} - {e}")
            return []


