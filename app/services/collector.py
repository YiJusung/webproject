import httpx
import logging
from datetime import datetime
from typing import List, Dict, Any

logger = logging.getLogger("hourly_pulse")

async def fetch_reddit_subreddit(subreddit: str, limit: int = 10) -> List[Dict[str, Any]]:
    """
    Reddit íŠ¹ì • ì„œë¸Œë ˆë”§ì—ì„œ ì¸ê¸° ê²Œì‹œë¬¼ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    Args:
        subreddit: ì„œë¸Œë ˆë”§ ì´ë¦„ (ì˜ˆ: "worldnews", "technology", "korea")
        limit: ìˆ˜ì§‘í•  ê²Œì‹œë¬¼ ìˆ˜
    
    Returns:
        ê²Œì‹œë¬¼ ì •ë³´ ë¦¬ìŠ¤íŠ¸ (title, url, upvotes ë“± í¬í•¨)
    """
    headers = {
        "User-Agent": "HourlyPulse/1.0 (by /u/hourlypulse)"
    }
    
    url = f"https://www.reddit.com/r/{subreddit}/hot.json?limit={limit}"
    
    logger.info(f"ğŸ”´ Reddit r/{subreddit} ìˆ˜ì§‘ ì‹œì‘...")
    
    async with httpx.AsyncClient(timeout=10.0, headers=headers, follow_redirects=True) as client:
        try:
            response = await client.get(url)
            response.raise_for_status()
            
            data = response.json()
            posts = []
            
            if "data" in data and "children" in data["data"]:
                for post_data in data["data"]["children"]:
                    post = post_data.get("data", {})
                    if post.get("title"):
                        post_item = {
                            "source": f"Reddit r/{subreddit}",
                            "title": post.get("title", "")[:200],  # ìµœëŒ€ 200ì
                            "url": f"https://reddit.com{post.get('permalink', '')}",
                            "upvotes": post.get("ups", 0),
                            "comments": post.get("num_comments", 0),
                            "subreddit": subreddit,
                            "collected_at": datetime.now().isoformat()
                        }
                        posts.append(post_item)
            
            if posts:
                logger.info(f"âœ… r/{subreddit} ìˆ˜ì§‘ ì„±ê³µ! {len(posts)}ê°œ ê²Œì‹œë¬¼ ë°œê²¬")
            return posts
            
        except httpx.HTTPStatusError as e:
            logger.error(f"âŒ r/{subreddit} HTTP ì˜¤ë¥˜ ({e.response.status_code}): {e}")
            return []
        except Exception as e:
            logger.error(f"âŒ r/{subreddit} ìˆ˜ì§‘ ì‹¤íŒ¨: {type(e).__name__} - {e}")
            return []


async def fetch_google_trends() -> List[Dict[str, Any]]:
    """
    Redditì˜ ì¸ê¸° ê²Œì‹œë¬¼ì„ ê°€ì ¸ì™€ì„œ íŠ¸ë Œë”© í† í”½ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    êµ¬ê¸€ íŠ¸ë Œë“œ RSSê°€ ë” ì´ìƒ ì œê³µë˜ì§€ ì•Šì•„ Reddit APIë¡œ ëŒ€ì²´í–ˆìŠµë‹ˆë‹¤.
    API Keyê°€ í•„ìš” ì—†ì–´ ë°”ë¡œ í…ŒìŠ¤íŠ¸í•˜ê¸° ì¢‹ìŠµë‹ˆë‹¤.
    
    Returns:
        ì¸ê¸° ê²Œì‹œë¬¼ ì •ë³´ ë¦¬ìŠ¤íŠ¸ (title, url, upvotes, comments í¬í•¨)
    """
    # Reddit APIëŠ” User-Agentê°€ í•„ìˆ˜ì…ë‹ˆë‹¤
    headers = {
        "User-Agent": "HourlyPulse/1.0 (by /u/hourlypulse)"
    }
    
    # Redditì˜ ì¸ê¸° ê²Œì‹œë¬¼ (r/popular ë˜ëŠ” íŠ¹ì • ì„œë¸Œë ˆë”§)
    # JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ë©ë‹ˆë‹¤ (4K RPM í™œìš©í•˜ì—¬ ìˆ˜ì§‘ëŸ‰ ì¦ê°€)
    url = "https://www.reddit.com/r/popular/hot.json?limit=50"  # 10 -> 50ìœ¼ë¡œ ì¦ê°€
    
    logger.info("ğŸŒ Reddit ì¸ê¸° ê²Œì‹œë¬¼ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    
    async with httpx.AsyncClient(timeout=10.0, headers=headers, follow_redirects=True) as client:
        try:
            response = await client.get(url)
            response.raise_for_status()
            
            data = response.json()
            
            # Reddit JSON êµ¬ì¡°: data -> children -> data -> title, upvotes, comments ë“±
            posts = []
            if "data" in data and "children" in data["data"]:
                for post_data in data["data"]["children"]:
                    post = post_data.get("data", {})
                    if post.get("title"):
                        title = post.get("title", "")
                        # ë„ˆë¬´ ê¸´ ì œëª©ì€ ì˜ë¼ë‚´ê¸°
                        if len(title) > 200:
                            title = title[:197] + "..."
                        
                        post_item = {
                            "source": "Reddit Popular",
                            "title": title,
                            "url": f"https://reddit.com{post.get('permalink', '')}",
                            "upvotes": post.get("ups", 0),
                            "comments": post.get("num_comments", 0),  # ëŒ“ê¸€ ìˆ˜ ì¶”ê°€
                            "subreddit": post.get("subreddit", "popular"),
                            "collected_at": datetime.now().isoformat()
                        }
                        posts.append(post_item)
            
            if posts:
                logger.info(f"âœ… ìˆ˜ì§‘ ì„±ê³µ! ì´ {len(posts)}ê°œì˜ ì¸ê¸° ê²Œì‹œë¬¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                return posts[:50]  # ìƒìœ„ 50ê°œ ë°˜í™˜
            else:
                logger.warning("âš ï¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
                
        except httpx.HTTPStatusError as e:
            logger.error(f"âŒ HTTP ì˜¤ë¥˜ ({e.response.status_code}): {e}")
            return []
        except Exception as e:
            logger.error(f"âŒ ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬ ë°œìƒ: {type(e).__name__} - {e}")
            return []

